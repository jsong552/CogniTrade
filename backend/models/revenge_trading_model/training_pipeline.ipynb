{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data preprocessing\n",
        "\n",
        "Notebook for preprocessing overtrading datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "664d95a6",
      "metadata": {},
      "source": [
        "## Concepts\n",
        "\n",
        "- **Session**: one fixed-time window (e.g., each 15-minute window is a session).\n",
        "- **Core window**: same as session in this setup.\n",
        "- **Overtrading indicators**: optional global summaries across all windows (for context only).\n",
        "\n",
        "This notebook builds one **training row per window**.\n",
        "\n",
        "**Note:** each row corresponds to a single window and includes both the core-window\n",
        "features and the per-window overtrading indicators.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "84167800",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\johnl\\Documents\\CogniTrade\\backend\\models\\revenge_trading_model\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "\n",
        "# Load mock behaviors datasets\n",
        "base_dir = Path('.').resolve()\n",
        "print(base_dir.absolute())\n",
        "\n",
        "sys.path.append(str(base_dir / '../..'))\n",
        "\n",
        "data_dir = (base_dir / '../../mock_behaviours').resolve()\n",
        "\n",
        "bias_present_file = (data_dir / 'revenge_example.csv').absolute()\n",
        "bias_negative_file = (data_dir / 'balanced_example.csv').absolute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "30aaa0fc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2200\n",
            "2200\n",
            "1200\n",
            "1200\n"
          ]
        }
      ],
      "source": [
        "from extract_features import extract_derived_features\n",
        "\n",
        "bias_present_df = extract_derived_features(bias_present_file)\n",
        "bias_negative_df = extract_derived_features(bias_negative_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "74854cb9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a baseline and post loss window, at each loss event\n",
        "bias_present_loss_events = bias_present_df[~bias_present_df['IsWin']]\n",
        "bias_negative_loss_events = bias_negative_df[~bias_negative_df['IsWin']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a87d9553",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_core_window_vector(win, eps) -> pd.DataFrame:\n",
        "    if win.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    win = win.copy()\n",
        "\n",
        "    start = win.iloc[0]['timestamp']\n",
        "    end = win.iloc[-1]['timestamp']\n",
        "\n",
        "\n",
        "    # Time / activity\n",
        "    n_trades = len(win)\n",
        "    window_minutes = (end - start).total_seconds() / 60\n",
        "    trade_rate_per_min = n_trades / window_minutes\n",
        "\n",
        "    gaps_sec = win['MinsSinceLastTrade'] * 60\n",
        "    median_gap_sec = gaps_sec.median()\n",
        "    mean_gap_sec   = gaps_sec.mean()\n",
        "\n",
        "    burst_frac = (gaps_sec <= 60).mean()\n",
        "\n",
        "    # Instrument churn\n",
        "    n_assets = win['asset'].nunique()\n",
        "\n",
        "    top_asset_share = (win['asset'].value_counts(normalize=True).iloc[0])\n",
        "\n",
        "    asset_changes = (win['asset'].ne(win['asset'].shift()).sum() - 1)\n",
        "    asset_switch_rate = asset_changes / max(n_trades - 1, 1)\n",
        "\n",
        "    # Sizing / turnover\n",
        "    sizing = win['TradeSize']\n",
        "\n",
        "    sizing_sum  = sizing.sum()\n",
        "    sizing_mean = sizing.mean()\n",
        "    sizing_std  = sizing.std()\n",
        "\n",
        "    window_start_balance = win.iloc[0][\"balance\"]\n",
        "    turnover = sizing_sum / (window_start_balance + eps)    # or sum TradeSizePctBalance\n",
        "\n",
        "    # P/L distribution\n",
        "    pnl = win['profit_loss']\n",
        "\n",
        "    pnl_sum  = pnl.sum()\n",
        "    pnl_mean = pnl.mean()\n",
        "    pnl_std  = pnl.std()\n",
        "\n",
        "    win_rate = win['IsWin'].mean()\n",
        "    positive_pnl = pnl[pnl > 0]\n",
        "    avg_gain = positive_pnl.mean() if not positive_pnl.empty else 0.0\n",
        "    negative_pnl = pnl[pnl < 0]\n",
        "    avg_loss_abs = negative_pnl.abs().mean() if not negative_pnl.empty else 0.0\n",
        "    payoff_ratio = avg_gain / (avg_loss_abs + eps)\n",
        "\n",
        "    pnl_skew_proxy = (pnl.quantile(0.9) + pnl.quantile(0.1)) / (abs(pnl.quantile(0.5)) + eps)\n",
        "\n",
        "    # Drawdown proxy\n",
        "    min_balance = win['balance'].min()\n",
        "    dd_max = (min_balance - window_start_balance) / window_start_balance\n",
        "\n",
        "\n",
        "    return {\n",
        "        # \"window_start\": str(start),\n",
        "        # \"window_end\": str(end),\n",
        "        \"n_trades\": n_trades,\n",
        "        \"trade_rate_per_min\": trade_rate_per_min,\n",
        "        \"median_gap_sec\": median_gap_sec,\n",
        "        \"mean_gap_sec\": mean_gap_sec,\n",
        "        # \"gap_cv\": gap_cv,\n",
        "        \"burst_frac\": burst_frac,\n",
        "        \"n_assets\": n_assets,\n",
        "        \"top_asset_share\": top_asset_share,\n",
        "        \"asset_switch_rate\": asset_switch_rate,\n",
        "        \"sizing_sum\": sizing_sum,\n",
        "        \"sizing_mean\": sizing_mean,\n",
        "        \"sizing_std\": sizing_std,\n",
        "        \"turnover\": turnover,\n",
        "        \"pnl_sum\": pnl_sum,\n",
        "        \"pnl_mean\": pnl_mean,\n",
        "        \"pnl_std\": pnl_std,\n",
        "        \"win_rate\": win_rate,\n",
        "        \"avg_gain\": avg_gain,\n",
        "        \"avg_loss_abs\": avg_loss_abs,\n",
        "        \"payoff_ratio\": payoff_ratio,\n",
        "        \"pnl_skew_proxy\": pnl_skew_proxy,\n",
        "        \"dd_max\": dd_max,\n",
        "        \"window_start_balance\": window_start_balance,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cb3c61ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_revenge_trading_window_vector(base, post, eps: float = 1e-9):\n",
        "    base = compute_core_window_vector(base, eps)\n",
        "    post = compute_core_window_vector(post, eps)\n",
        "\n",
        "    # REVENGE TRADING INDICATORS\n",
        "    post_trade_rate_ratio = post['trade_rate_per_min'] / (base['trade_rate_per_min'] + eps)\n",
        "    post_turnover_ratio   = post['turnover'] / (base['turnover'] + eps)\n",
        "    post_sizing_mean_ratio = post['sizing_mean'] / (base['sizing_mean'] + eps)\n",
        "\n",
        "    post_win_rate_delta = post['win_rate'] - base['win_rate']\n",
        "    post_pnl_vol_ratio  = post['pnl_std'] / (base['pnl_std'] + eps)\n",
        "\n",
        "    post_asset_switch_delta = post['asset_switch_rate'] - base['asset_switch_rate']\n",
        "    post_burst_frac_delta   = post['burst_frac'] - base['burst_frac']\n",
        "\n",
        "    vec = {\n",
        "        'post_trade_rate_ratio': post_trade_rate_ratio,\n",
        "        'post_turnover_delta': post_turnover_ratio,\n",
        "        'post_sizing_mean_ratio': post_sizing_mean_ratio,\n",
        "        'post_win_rate_delta': post_win_rate_delta,\n",
        "        'post_pnl_vol_ratio': post_pnl_vol_ratio,\n",
        "        'post_asset_switch_delta': post_asset_switch_delta,\n",
        "        'post_burst_frac_delta': post_burst_frac_delta,\n",
        "    }\n",
        "    # print('---------------------------------------------------------------')\n",
        "    # print(base)\n",
        "    # print(post)\n",
        "    return vec | post    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6cce202",
      "metadata": {},
      "source": [
        "## Training dataframe (one row per window)\n",
        "\n",
        "Each window is treated as a session, so the training dataframe is simply the\n",
        "core window features with a `session_id` per window.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "013fdd56",
      "metadata": {},
      "outputs": [],
      "source": [
        "BASELINE_WIN_SIZE = 15\n",
        "POSTLOSS_WIN_SIZE = 5\n",
        "MIN_WIN=3\n",
        "\n",
        "samples = pd.DataFrame()\n",
        "\n",
        "for idx, loss in bias_present_loss_events.iterrows():\n",
        "    base_start = max(0, idx - BASELINE_WIN_SIZE)\n",
        "    post_end = min(idx + POSTLOSS_WIN_SIZE, len(bias_present_df))\n",
        "    baseline = bias_present_df.iloc[base_start:idx]\n",
        "    postloss = bias_present_df.iloc[idx:post_end]\n",
        "\n",
        "    if len(baseline) > MIN_WIN and len(postloss) > MIN_WIN:\n",
        "        vec = compute_revenge_trading_window_vector(baseline, postloss)\n",
        "        vec['revenge_trader_window'] = 1\n",
        "        # print(vec)\n",
        "        samples = pd.concat([samples, pd.DataFrame([vec])], ignore_index=True)\n",
        "\n",
        "\n",
        "for idx, loss in bias_negative_df.iterrows():\n",
        "    base_start = max(0, idx - BASELINE_WIN_SIZE)\n",
        "    post_end = min(idx + POSTLOSS_WIN_SIZE, len(bias_negative_df))\n",
        "    baseline = bias_negative_df.iloc[base_start:idx]\n",
        "    postloss = bias_negative_df.iloc[idx:post_end]\n",
        "\n",
        "    if len(baseline) > MIN_WIN and len(postloss) > MIN_WIN:\n",
        "        vec = compute_revenge_trading_window_vector(baseline, postloss)\n",
        "        vec['revenge_trader_window'] = 0\n",
        "        # print(vec)\n",
        "        samples = pd.concat([samples, pd.DataFrame([vec])], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2b160924",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [post_trade_rate_ratio, post_turnover_delta, post_sizing_mean_ratio, post_win_rate_delta, post_pnl_vol_ratio, post_asset_switch_delta, post_burst_frac_delta, n_trades, trade_rate_per_min, median_gap_sec, mean_gap_sec, burst_frac, n_assets, top_asset_share, asset_switch_rate, sizing_sum, sizing_mean, sizing_std, turnover, pnl_sum, pnl_mean, pnl_std, win_rate, avg_gain, avg_loss_abs, payoff_ratio, pnl_skew_proxy, dd_max, window_start_balance, revenge_trader_window]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "samples\n",
        "\n",
        "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
        "    print(samples[samples.isna().any(axis=1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8fb4b45b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['revenge_model.joblib']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
        "import joblib\n",
        "\n",
        "# -----------------------------\n",
        "# Step 0: Prepare data\n",
        "# -----------------------------\n",
        "# X = [[n_trades, trade_rate, gap_mean, gap_std, n_assets, top_asset_share, turnover, win_rate, ...], ...]\n",
        "# y = [1, 0, 0, 1, ...]  # 1 = revenge_trader window, 0 = calm_trader window\n",
        "label = 'revenge_trader_window'\n",
        "feature_cols = [k for k in samples.columns if k != label]\n",
        "X = samples[feature_cols].to_numpy(dtype=float)\n",
        "y = samples[label].to_numpy(dtype=float)\n",
        "\n",
        "X = np.array(X)  # shape (num_windows, num_features)\n",
        "y = np.array(y)    # shape (num_windows,)\n",
        "\n",
        "# -----------------------------\n",
        "# Step 1: Split into train/val\n",
        "# -----------------------------\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Step 2: Train Gradient Boosted Decision Tree classifier\n",
        "# -----------------------------\n",
        "model = GradientBoostingClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# model.fit(\n",
        "#     X_train, y_train,\n",
        "#     eval_set=[(X_val, y_val)],\n",
        "#     early_stopping_rounds=20,\n",
        "#     verbose=True\n",
        "# )\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Step 3: Evaluate\n",
        "# -----------------------------\n",
        "y_pred_proba = model.predict_proba(X_val)[:, 1]  # probability of revenge\n",
        "# y_pred = (y_pred_proba >= 0.5).astype(int)    # probability of revenge_trader_window=1\n",
        "\n",
        "# some accuracy stuff\n",
        "# print(\"Accuracy:\", accuracy_score(y_val, y_pred_proba))\n",
        "# print(\"ROC-AUC:\", roc_auc_score(y_val, y_pred_proba))\n",
        "# print(classification_report(y_val, y_pred_proba))\n",
        "\n",
        "\n",
        "# SAVE MODEL\n",
        "artifact = {\n",
        "    \"model\": model,\n",
        "    \"feature_keys\": feature_cols,   # order matters!\n",
        "    \"threshold\": 0.7,               # or whatever you choose\n",
        "    \"window_config\": {\n",
        "        \"baseline_num_trades\": BASELINE_WIN_SIZE,\n",
        "        \"postloss_num_trades\": POSTLOSS_WIN_SIZE\n",
        "    }\n",
        "}\n",
        "\n",
        "joblib.dump(artifact, 'revenge_model.joblib')\n",
        "\n",
        "\n",
        "# y_proba = model.predict_proba(X)[:, 1]\n",
        "# samples['pred_revenge_trader_window'] = y_proba\n",
        "\n",
        "# samples.to_csv(base_dir / 'revenge_out.csv')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
